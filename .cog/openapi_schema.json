{"components":{"schemas":{"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"title":"Detail","type":"array"}},"title":"HTTPValidationError","type":"object"},"Input":{"properties":{"apply_watermark":{"default":true,"description":"Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.","title":"Apply Watermark","type":"boolean","x-order":11},"condition_scale":{"default":0.5,"description":"The bigger this number is, the more ControlNet interferes","maximum":1,"minimum":0,"title":"Condition Scale","type":"number","x-order":3},"guidance_scale":{"default":7.5,"description":"Scale for classifier-free guidance","maximum":50,"minimum":1,"title":"Guidance Scale","type":"number","x-order":7},"image":{"description":"Input image for img2img or inpaint mode","format":"uri","title":"Image","type":"string","x-order":2},"lora_scale":{"default":0.6,"description":"LoRA additive scale. Only applicable on trained models.","maximum":1,"minimum":0,"title":"Lora Scale","type":"number","x-order":12},"lora_weights":{"description":"Replicate LoRA weights to use. Leave blank to use the default weights.","title":"Lora Weights","type":"string","x-order":13},"negative_prompt":{"default":"","description":"Input Negative Prompt","title":"Negative Prompt","type":"string","x-order":1},"num_inference_steps":{"default":50,"description":"Number of denoising steps","maximum":500,"minimum":1,"title":"Num Inference Steps","type":"integer","x-order":6},"num_outputs":{"default":1,"description":"Number of images to output","maximum":4,"minimum":1,"title":"Num Outputs","type":"integer","x-order":4},"prompt":{"default":"An astronaut riding a rainbow unicorn","description":"Input prompt","title":"Prompt","type":"string","x-order":0},"refine":{"allOf":[{"$ref":"#/components/schemas/refine"}],"default":"base_image_refiner","description":"Whether to use refinement steps or not","x-order":9},"refine_steps":{"default":10,"description":"For base_image_refiner, the number of steps to refine","title":"Refine Steps","type":"integer","x-order":10},"scheduler":{"allOf":[{"$ref":"#/components/schemas/scheduler"}],"default":"K_EULER","description":"scheduler","x-order":5},"seed":{"description":"Random seed. Leave blank to randomize the seed","title":"Seed","type":"integer","x-order":8}},"title":"Input","type":"object"},"Output":{"items":{"format":"uri","type":"string"},"title":"Output","type":"array"},"PredictionRequest":{"properties":{"created_at":{"format":"date-time","title":"Created At","type":"string"},"id":{"title":"Id","type":"string"},"input":{"$ref":"#/components/schemas/Input"},"output_file_prefix":{"title":"Output File Prefix","type":"string"},"webhook":{"format":"uri","maxLength":65536,"minLength":1,"title":"Webhook","type":"string"},"webhook_events_filter":{"default":["start","output","logs","completed"],"items":{"$ref":"#/components/schemas/WebhookEvent"},"type":"array"}},"title":"PredictionRequest","type":"object"},"PredictionResponse":{"properties":{"completed_at":{"format":"date-time","title":"Completed At","type":"string"},"created_at":{"format":"date-time","title":"Created At","type":"string"},"error":{"title":"Error","type":"string"},"id":{"title":"Id","type":"string"},"input":{"$ref":"#/components/schemas/Input"},"logs":{"default":"","title":"Logs","type":"string"},"metrics":{"title":"Metrics","type":"object"},"output":{"$ref":"#/components/schemas/Output"},"started_at":{"format":"date-time","title":"Started At","type":"string"},"status":{"$ref":"#/components/schemas/Status"},"version":{"title":"Version","type":"string"}},"title":"PredictionResponse","type":"object"},"Status":{"description":"An enumeration.","enum":["starting","processing","succeeded","canceled","failed"],"title":"Status","type":"string"},"TrainingInput":{"properties":{"caption_prefix":{"default":"a photo of TOK, ","description":"Text which will be used as prefix during automatic captioning. Must contain the `token_string`. For example, if caption text is 'a photo of TOK', automatic captioning will expand to 'a photo of TOK under a bridge', 'a photo of TOK holding a cup', etc.","title":"Caption Prefix","type":"string","x-order":14},"checkpointing_steps":{"default":999999,"description":"Number of steps between saving checkpoints. Set to very very high number to disable checkpointing, because you don't need one.","title":"Checkpointing Steps","type":"integer","x-order":20},"clipseg_temperature":{"default":1,"description":"How blurry you want the CLIPSeg mask to be. We recommend this value be something between `0.5` to `1.0`. If you want to have more sharp mask (but thus more errorful), you can decrease this value.","title":"Clipseg Temperature","type":"number","x-order":18},"crop_based_on_salience":{"default":true,"description":"If you want to crop the image to `target_size` based on the important parts of the image, set this to True. If you want to crop the image based on face detection, set this to False","title":"Crop Based On Salience","type":"boolean","x-order":16},"input_images":{"description":"A .zip or .tar file containing the image files that will be used for fine-tuning","format":"uri","title":"Input Images","type":"string","x-order":0},"input_images_filetype":{"allOf":[{"$ref":"#/components/schemas/input_images_filetype"}],"default":"infer","description":"Filetype of the input images. Can be either `zip` or `tar`. By default its `infer`, and it will be inferred from the ext of input file.","x-order":21},"is_lora":{"default":true,"description":"Whether to use LoRA training. If set to False, will use Full fine tuning","title":"Is Lora","type":"boolean","x-order":6},"lora_lr":{"default":0.0001,"description":"Scaling of learning rate for training LoRA embeddings. Don't alter unless you know what you're doing.","title":"Lora Lr","type":"number","x-order":9},"lora_rank":{"default":32,"description":"Rank of LoRA embeddings. Don't alter unless you know what you're doing.","title":"Lora Rank","type":"integer","x-order":10},"lr_scheduler":{"allOf":[{"$ref":"#/components/schemas/lr_scheduler"}],"default":"constant","description":"Learning rate scheduler to use for training","x-order":11},"lr_warmup_steps":{"default":100,"description":"Number of warmup steps for lr schedulers with warmups.","title":"Lr Warmup Steps","type":"integer","x-order":12},"mask_target_prompts":{"description":"Prompt that describes part of the image that you will find important. For example, if you are fine-tuning your pet, `photo of a dog` will be a good prompt. Prompt-based masking is used to focus the fine-tuning process on the important/salient parts of the image","title":"Mask Target Prompts","type":"string","x-order":15},"max_train_steps":{"default":1000,"description":"Number of individual training steps. Takes precedence over num_train_epochs","title":"Max Train Steps","type":"integer","x-order":5},"num_train_epochs":{"default":4000,"description":"Number of epochs to loop through your training dataset","title":"Num Train Epochs","type":"integer","x-order":4},"resolution":{"default":768,"description":"Square pixel resolution which your images will be resized to for training","title":"Resolution","type":"integer","x-order":2},"seed":{"description":"Random seed for reproducible training. Leave empty to use a random seed","title":"Seed","type":"integer","x-order":1},"ti_lr":{"default":0.0003,"description":"Scaling of learning rate for training textual inversion embeddings. Don't alter unless you know what you're doing.","title":"Ti Lr","type":"number","x-order":8},"token_string":{"default":"TOK","description":"A unique string that will be trained to refer to the concept in the input images. Can be anything, but TOK works well","title":"Token String","type":"string","x-order":13},"train_batch_size":{"default":4,"description":"Batch size (per device) for training","title":"Train Batch Size","type":"integer","x-order":3},"unet_learning_rate":{"default":0.000001,"description":"Learning rate for the U-Net. We recommend this value to be somewhere between `1e-6` to `1e-5`.","title":"Unet Learning Rate","type":"number","x-order":7},"use_face_detection_instead":{"default":false,"description":"If you want to use face detection instead of CLIPSeg for masking. For face applications, we recommend using this option.","title":"Use Face Detection Instead","type":"boolean","x-order":17},"verbose":{"default":true,"description":"verbose output","title":"Verbose","type":"boolean","x-order":19}},"required":["input_images"],"title":"TrainingInput","type":"object"},"TrainingOutput":{"properties":{"weights":{"format":"uri","title":"Weights","type":"string"}},"required":["weights"],"title":"TrainingOutput","type":"object"},"TrainingRequest":{"properties":{"created_at":{"format":"date-time","title":"Created At","type":"string"},"id":{"title":"Id","type":"string"},"input":{"$ref":"#/components/schemas/TrainingInput"},"output_file_prefix":{"title":"Output File Prefix","type":"string"},"webhook":{"format":"uri","maxLength":65536,"minLength":1,"title":"Webhook","type":"string"},"webhook_events_filter":{"default":["start","output","logs","completed"],"items":{"$ref":"#/components/schemas/WebhookEvent"},"type":"array"}},"title":"TrainingRequest","type":"object"},"TrainingResponse":{"properties":{"completed_at":{"format":"date-time","title":"Completed At","type":"string"},"created_at":{"format":"date-time","title":"Created At","type":"string"},"error":{"title":"Error","type":"string"},"id":{"title":"Id","type":"string"},"input":{"$ref":"#/components/schemas/TrainingInput"},"logs":{"default":"","title":"Logs","type":"string"},"metrics":{"title":"Metrics","type":"object"},"output":{"$ref":"#/components/schemas/TrainingOutput"},"started_at":{"format":"date-time","title":"Started At","type":"string"},"status":{"$ref":"#/components/schemas/Status"},"version":{"title":"Version","type":"string"}},"title":"TrainingResponse","type":"object"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"title":"Location","type":"array"},"msg":{"title":"Message","type":"string"},"type":{"title":"Error Type","type":"string"}},"required":["loc","msg","type"],"title":"ValidationError","type":"object"},"WebhookEvent":{"description":"An enumeration.","enum":["start","output","logs","completed"],"title":"WebhookEvent","type":"string"},"input_images_filetype":{"description":"An enumeration.","enum":["zip","tar","infer"],"title":"input_images_filetype","type":"string"},"lr_scheduler":{"description":"An enumeration.","enum":["constant","linear"],"title":"lr_scheduler","type":"string"},"refine":{"description":"An enumeration.","enum":["no_refiner","base_image_refiner"],"title":"refine","type":"string"},"scheduler":{"description":"An enumeration.","enum":["DDIM","DPMSolverMultistep","HeunDiscrete","KarrasDPM","K_EULER_ANCESTRAL","K_EULER","PNDM"],"title":"scheduler","type":"string"}}},"info":{"title":"Cog","version":"0.1.0"},"openapi":"3.0.2","paths":{"/":{"get":{"operationId":"root__get","responses":{"200":{"content":{"application/json":{"schema":{"title":"Response Root  Get"}}},"description":"Successful Response"}},"summary":"Root"}},"/health-check":{"get":{"operationId":"healthcheck_health_check_get","responses":{"200":{"content":{"application/json":{"schema":{"title":"Response Healthcheck Health Check Get"}}},"description":"Successful Response"}},"summary":"Healthcheck"}},"/predictions":{"post":{"description":"Run a single prediction on the model","operationId":"predict_predictions_post","parameters":[{"in":"header","name":"prefer","required":false,"schema":{"title":"Prefer","type":"string"}}],"requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PredictionRequest"}}}},"responses":{"200":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PredictionResponse"}}},"description":"Successful Response"},"422":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}},"description":"Validation Error"}},"summary":"Predict"}},"/predictions/{prediction_id}":{"put":{"description":"Run a single prediction on the model (idempotent creation).","operationId":"predict_idempotent_predictions__prediction_id__put","parameters":[{"in":"path","name":"prediction_id","required":true,"schema":{"title":"Prediction ID","type":"string"}},{"in":"header","name":"prefer","required":false,"schema":{"title":"Prefer","type":"string"}}],"requestBody":{"content":{"application/json":{"schema":{"allOf":[{"$ref":"#/components/schemas/PredictionRequest"}],"title":"Prediction Request"}}},"required":true},"responses":{"200":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PredictionResponse"}}},"description":"Successful Response"},"422":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}},"description":"Validation Error"}},"summary":"Predict Idempotent"}},"/predictions/{prediction_id}/cancel":{"post":{"description":"Cancel a running prediction","operationId":"cancel_predictions__prediction_id__cancel_post","parameters":[{"in":"path","name":"prediction_id","required":true,"schema":{"title":"Prediction ID","type":"string"}}],"responses":{"200":{"content":{"application/json":{"schema":{"title":"Response Cancel Predictions  Prediction Id  Cancel Post"}}},"description":"Successful Response"},"422":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}},"description":"Validation Error"}},"summary":"Cancel"}},"/shutdown":{"post":{"operationId":"start_shutdown_shutdown_post","responses":{"200":{"content":{"application/json":{"schema":{"title":"Response Start Shutdown Shutdown Post"}}},"description":"Successful Response"}},"summary":"Start Shutdown"}},"/trainings":{"post":{"operationId":"train_trainings_post","parameters":[{"in":"header","name":"prefer","required":false,"schema":{"title":"Prefer","type":"string"}}],"requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TrainingRequest"}}}},"responses":{"200":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/TrainingResponse"}}},"description":"Successful Response"},"422":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}},"description":"Validation Error"}},"summary":"Train"}},"/trainings/{training_id}":{"put":{"operationId":"train_idempotent_trainings__training_id__put","parameters":[{"in":"path","name":"training_id","required":true,"schema":{"title":"Training ID","type":"string"}},{"in":"header","name":"prefer","required":false,"schema":{"title":"Prefer","type":"string"}}],"requestBody":{"content":{"application/json":{"schema":{"allOf":[{"$ref":"#/components/schemas/TrainingRequest"}],"title":"Training Request"}}},"required":true},"responses":{"200":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/PredictionResponse"}}},"description":"Successful Response"},"422":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}},"description":"Validation Error"}},"summary":"Train Idempotent"}},"/trainings/{training_id}/cancel":{"post":{"operationId":"cancel_training_trainings__training_id__cancel_post","parameters":[{"in":"path","name":"training_id","required":true,"schema":{"title":"Training ID","type":"string"}}],"responses":{"200":{"content":{"application/json":{"schema":{"title":"Response Cancel Training Trainings  Training Id  Cancel Post"}}},"description":"Successful Response"},"422":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}},"description":"Validation Error"}},"summary":"Cancel Training"}}}}